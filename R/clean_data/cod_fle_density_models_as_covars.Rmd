---
title: "Fit cod and flounder density models which are used as covariates in the condition model"
author: "Max Lindmark"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
  df_print: paged
pdf_document: default
editor_options: 
  chunk_output_type: console
---
  
```{r setup, include = FALSE, cache=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align ='center'
)
```

# Intro
In this script, I fit simplified models to density data so that I can predict densities on the condition data and pred grid

## Load libraries

```{r, message=FALSE}
library(tidyverse)
library(readxl)
library(tidylog)
library(RCurl)
library(viridis)
library(RColorBrewer)
library(patchwork)
library(janitor)
library(icesDatras)
library(mapdata)
library(patchwork)
library(rgdal)
library(raster)
library(sf)
library(rgeos)
library(chron)
library(lattice)
library(ncdf4)
library(marmap)
library(rnaturalearth)
library(rnaturalearthdata)
library(mapplots)
library(geosphere)
#remotes::install_github("pbs-assess/sdmTMB")
library(sdmTMB)

theme_plot <- function(base_size = 11, base_family = "") {
  theme_light(base_size = base_size, base_family = "") +
    theme(
      axis.text = element_text(size = 9),
      legend.text = element_text(size = 9),
      legend.title = element_text(size = 9),
      legend.position = "bottom",
      legend.key.height = unit(0.2, "cm"),
      legend.margin = margin(0, 0, 0, 0),
      legend.box.margin = margin(-5, -5, -5, -5),
      strip.text = element_text(size = 9, colour = 'gray10', margin = margin(b = 1, t = 1)),
      strip.background = element_rect(fill = "grey95")
      )
}

# To load entire cache in interactive r session, do:
# qwraps2::lazyload_cache_dir(path = "R/clean_data/cod_fle_density_models_as_covars_cache/html")
```

## For maps

```{r read coastline data, message=FALSE, warning=FALSE}
world <- ne_countries(scale = "medium", returnclass = "sf")

# Specify map ranges
ymin = 54; ymax = 58; xmin = 12; xmax = 22

map_data <- rnaturalearth::ne_countries(
  scale = "medium",
  returnclass = "sf", continent = "europe")

# Crop the polygon for plotting and efficiency:
# st_bbox(map_data) # find the rough coordinates
sf::sf_use_s2(FALSE)
swe_coast <- suppressWarnings(suppressMessages(
  st_crop(map_data,
          c(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax))))

# Transform our map into UTM 33 coordinates, which is the equal-area projection we fit in:
utm_zone33 <- 32633
swe_coast_proj <- sf::st_transform(swe_coast, crs = utm_zone33)

#ggplot(swe_coast_proj) + geom_sf() 
```

## Load data

```{r, message=FALSE, cache=TRUE}
d <- readr::read_csv("https://raw.githubusercontent.com/maxlindmark/cod_condition/master/data/for_analysis/catch_q_1_4.csv")

# Filter to match the data I want to predict on
d <- d %>% filter(year > 1992 & year < 2020 & quarter == 4)

# Calculate standardized variables
d <- d %>% 
  mutate(depth_sc = (depth - mean(depth))/sd(depth)) %>%
  mutate(year = as.integer(year)) %>% 
  drop_na(depth) %>% 
  rename("density_cod" = "density") # to fit better with how flounder is named

# Explore data a bit
ggplot(d) + 
  geom_point(aes(year, density_cod, color = factor(sub_div))) + 
  facet_wrap(~sub_div)

ggplot(d) + 
  geom_point(aes(year, density_fle, color = factor(sub_div))) + 
  facet_wrap(~sub_div)

ggplot(d) + 
  geom_point(aes(X*1000, Y*1000, color = density_fle)) + 
  facet_wrap(~year)

d %>% 
  group_by(year) %>% 
  summarise(n_haul = length(unique(haul.id))) %>% 
  ggplot(aes(year, n_haul)) +
  geom_line()
  
nrow(d)

summary(d$density_fle)
```

## Make mesh

```{r make mesh}
# Make mesh:
spde <- make_mesh(d, xy_cols = c("X", "Y"),
                  n_knots = 200, 
                  type = "kmeans", seed = 42)

plot(spde)
```

## Fit models

```{r fit cod models, cache=TRUE}
# Depth spline + oxy spline
# Cod model
mcod <- sdmTMB(density_cod ~ 0 + as.factor(year) + s(depth_sc),
               data = d,
               mesh = spde, family = tweedie(link = "log"),
               spatiotemporal = "AR1",
               spatial = "on",
               time = "year",
               reml = FALSE,
               control = sdmTMBcontrol(newton_steps = 1))

tidy(mcod, conf.int = TRUE)
```

```{r, check convergence of cod model}
sanity(mcod)
```

```{r, run extra optimization for cod, cache=TRUE}
mcod_1 <- run_extra_optimization(mcod, nlminb_loops = 1, newton_loops = 1)

sanity(mcod_1)
```

```{r, MCMC residuals of cod model}
mcmc_res <- residuals(mcod, type = "mle-mcmc", mcmc_iter = 201, mcmc_warmup = 200)

qqnorm(mcmc_res);qqline(mcmc_res)
```

```{r save cod model}
# Save model (so that I can add density predictions to the pred grid for condition)
saveRDS(mcod_1, "output/mcod.rds")
```

```{r fit fle models, cache=TRUE}
# Fit flounder model
mfle <- sdmTMB(density_fle ~ 0 + as.factor(year) + s(depth_sc),
               data = d,
               mesh = spde,
               family = tweedie(link = "log"),
               spatiotemporal = "AR1",
               spatial = "on",
               time = "year",
               reml = FALSE,
               control = sdmTMBcontrol(newton_steps = 1))

tidy(mfle, conf.int = TRUE)
```

```{r, check convergence of flounder model}
sanity(mfle)
```

```{r, run extra optimization for flounder, cache=TRUE}
mfle_1 <- run_extra_optimization(mfle, nlminb_loops = 1, newton_loops = 1)
sanity(mfle_1)
```

```{r, MCMC residuals of flounder model}
mcmc_res_fle <- residuals(mfle_1, type = "mle-mcmc", mcmc_iter = 201, mcmc_warmup = 200)

qqnorm(mcmc_res_fle);qqline(mcmc_res_fle)
```

```{r save flounder model}
# Save model (so that I can add density predictions to the pred grid for condition)
saveRDS(mfle_1, "output/mfle.rds")
```

## Now that the models have been fit, I can create the `pred_gid` (make_pred_grid_utm.R)

```{r}
knitr::knit_exit()
```

## [Extra for bentfish - calculate biomass index per subdivision]: Requires making the pred grid first

## Load prediction grid

```{r pred grid}
pred_grid1 <- readr::read_csv("https://raw.githubusercontent.com/maxlindmark/cod-condition/master/data/for_analysis/pred_grid_(1_2).csv")
pred_grid <- readr::read_csv("https://raw.githubusercontent.com/maxlindmark/cod-condition/master/data/for_analysis/pred_grid_(2_2).csv")

pred_grid <- bind_rows(pred_grid1, pred_grid)

# Standardize depth with respect to data
pred_grid <- pred_grid %>%
  mutate(year = as.integer(year)) %>% 
  filter(year %in% c(unique(d$year))) %>% 
  mutate(depth_sc = (depth - mean(d$depth))/sd(d$depth),
         temp_sc = (temp - mean(d$temp))/sd(d$temp),
         oxy_sc = (oxy - mean(d$oxy))/sd(d$oxy)) %>% # Need to scale these to the mean and sd in the data!
  drop_na(oxy, depth, temp)
```

```{r calculate total indexes, cachce=TRUE}
preds_cod_sim <- predict(mcod_1, newdata = pred_grid, nsim = 100)
 
preds_fle_sim <- predict(mfle_1, newdata = pred_grid, nsim = 100)

index_fle_sim <- get_index_sims(preds_fle_sim,
                                area = rep(4*4, nrow(preds_fle_sim)))

index_fle_sims <- get_index_sims(preds_fle_sim,
                                 area = rep(4*4, nrow(preds_fle_sim)),
                                 return_sims = TRUE)

index_cod_sim <- get_index_sims(preds_cod_sim,
                                area = rep(4*4, nrow(preds_cod_sim)))

index_cod_sims <- get_index_sims(preds_cod_sim,
                                 area = rep(4*4, nrow(preds_cod_sim)),
                                 return_sims = TRUE)

sim <- bind_rows(index_fle_sim %>% mutate(Species = "Flounder"),
                 index_cod_sim %>% mutate(Species = "Cod"))

sims <- bind_rows(index_fle_sims %>% mutate(Species = "Flounder"),
                  index_cod_sims %>% mutate(Species = "Cod"))

# Plot
sims %>% 
  filter(.iteration < 26) %>% 
  ggplot() +
  facet_wrap(~Species, ncol = 1, scales = "free") +
  #facet_wrap(~Species, ncol = 3, scales = "free") +
  geom_ribbon(data = sim, aes(year, est, ymin = lwr, ymax = upr, color = Species, fill = Species), alpha = 0.2, color = NA) +
  geom_line(aes(year, .value, group = .iteration, color = Species), alpha = 0.2) +
  geom_line(data = sim, aes(year, est, color = Species), size = 0.5) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal(base_size = 18) +
  guides(color = "none",
         fill = "none") +
  xlab('Year') +
  ylab('Biomass [kg]') +
  NULL

ggsave("figures/supp/density/cod_fle_index.png", width = 6.5, height = 8.5, dpi = 600)

data.frame(Cod = filter(sim, Species == "Cod")$est,
                 Flounder = filter(sim, Species == "Flounder")$est) %>% 
  ggplot(aes(Cod, Flounder)) + 
  geom_point(size = 3, alpha = 0.8) + 
  theme_minimal(base_size = 18) +
  theme(aspect.ratio = 1)

ggsave("figures/supp/density/cod_fle_index_corr.png", width = 6.5, height = 6.5, dpi = 600)
```

```{r calculate indexes, cachce=TRUE}
### Cod
# SD 24
preds_cod24_sim <- predict(mcod_1, newdata = filter(pred_grid, sub_div == 24), nsim = 100)

# SD 25
preds_cod25_sim <- predict(mcod_1, newdata = filter(pred_grid, sub_div == 25), nsim = 100)

# SD 26
preds_cod26_sim <- predict(mcod_1, newdata = filter(pred_grid, sub_div == 26), nsim = 100)

# SD 27
preds_cod27_sim <- predict(mcod_1, newdata = filter(pred_grid, sub_div == 27), nsim = 100)

# SD 28
preds_cod28_sim <- predict(mcod_1, newdata = filter(pred_grid, sub_div == 28), nsim = 100)

# Now calculate the CPUE index (average)
index24_cod_sim <- get_index_sims(preds_cod24_sim, area = rep(4*4, nrow(preds_cod24_sim)))
index25_cod_sim <- get_index_sims(preds_cod25_sim, area = rep(4*4, nrow(preds_cod25_sim)))
index26_cod_sim <- get_index_sims(preds_cod26_sim, area = rep(4*4, nrow(preds_cod26_sim)))
index27_cod_sim <- get_index_sims(preds_cod27_sim, area = rep(4*4, nrow(preds_cod27_sim)))
index28_cod_sim <- get_index_sims(preds_cod28_sim, area = rep(4*4, nrow(preds_cod28_sim)))

# Add some columns
index24_cod_sim <- index24_cod_sim %>% mutate(sub_div = "24", species = "cod")
index25_cod_sim <- index25_cod_sim %>% mutate(sub_div = "25", species = "cod")
index26_cod_sim <- index26_cod_sim %>% mutate(sub_div = "26", species = "cod")
index27_cod_sim <- index27_cod_sim %>% mutate(sub_div = "27", species = "cod")
index28_cod_sim <- index28_cod_sim %>% mutate(sub_div = "28", species = "cod")


### Flounder
# SD 24
preds_fle24_sim <- predict(mfle_1, newdata = filter(pred_grid, sub_div == 24), nsim = 100)

# SD 25
preds_fle25_sim <- predict(mfle_1, newdata = filter(pred_grid, sub_div == 25), nsim = 100)

# SD 26
preds_fle26_sim <- predict(mfle_1, newdata = filter(pred_grid, sub_div == 26), nsim = 100)

# SD 27
preds_fle27_sim <- predict(mfle_1, newdata = filter(pred_grid, sub_div == 27), nsim = 100)

# SD 28
preds_fle28_sim <- predict(mfle_1, newdata = filter(pred_grid, sub_div == 28), nsim = 100)

# Now calculate the CPUE index (average)
index24_fle_sim <- get_index_sims(preds_fle24_sim, area = rep(4*4, nrow(preds_fle24_sim)))
index25_fle_sim <- get_index_sims(preds_fle25_sim, area = rep(4*4, nrow(preds_fle25_sim)))
index26_fle_sim <- get_index_sims(preds_fle26_sim, area = rep(4*4, nrow(preds_fle26_sim)))
index27_fle_sim <- get_index_sims(preds_fle27_sim, area = rep(4*4, nrow(preds_fle27_sim)))
index28_fle_sim <- get_index_sims(preds_fle28_sim, area = rep(4*4, nrow(preds_fle28_sim)))

# Add some columns
index24_fle_sim <- index24_fle_sim %>% mutate(sub_div = "24", species = "fle")
index25_fle_sim <- index25_fle_sim %>% mutate(sub_div = "25", species = "fle")
index26_fle_sim <- index26_fle_sim %>% mutate(sub_div = "26", species = "fle")
index27_fle_sim <- index27_fle_sim %>% mutate(sub_div = "27", species = "fle")
index28_fle_sim <- index28_fle_sim %>% mutate(sub_div = "28", species = "fle")

div_index_sim <- bind_rows(index24_cod_sim, index25_cod_sim, index26_cod_sim, index27_cod_sim, index28_cod_sim,
                           index24_fle_sim, index25_fle_sim, index26_fle_sim, index27_fle_sim, index28_fle_sim) %>% 
  mutate(est_t = est/1000, lwr_t = lwr/1000, upr_t = upr/1000) # convert to tonnes 
```

Plot the index and save as csv

```{r plot and save index}
ggplot(div_index_sim, aes(year, est_t, color = sub_div)) +
  geom_line() +
  facet_wrap(~species, scales = "free") +
  geom_ribbon(aes(year, ymin = lwr_t, ymax = upr_t, fill = sub_div), alpha = 0.2) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2", name = "ICES subdivision") +
  guides(color = "none") + 
  labs(x = "Year", y = "Tonnes", fill = "Sub Divisions") +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom",
        legend.key.height = unit(0.2, "cm"),
        legend.key.width = unit(0.2, "cm"),
        legend.background = element_blank(),
        plot.margin = unit(c(0, 0.25, 0.15, 0), "cm")) +
  NULL

ggplot(div_index_sim, aes(year, est_t, color = sub_div)) +
  geom_line() +
  facet_wrap(~species, scales = "free") +
  #geom_ribbon(aes(year, ymin = lwr_t, ymax = upr_t, fill = sub_div), alpha = 0.2) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2", name = "ICES subdivision") +
  guides(color = "none") + 
  labs(x = "Year", y = "Tonnes", fill = "Sub Divisions") +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom",
        legend.key.height = unit(0.2, "cm"),
        legend.key.width = unit(0.2, "cm"),
        legend.background = element_blank(),
        plot.margin = unit(c(0, 0.25, 0.15, 0), "cm")) +
  NULL

ggplot(div_index_sim, aes(year, est_t, color = species)) +
  geom_line() +
  facet_wrap(~sub_div, scales = "free") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2", name = "ICES subdivision") +
  labs(x = "Year", y = "Tonnes", fill = "Sub Divisions") +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom",
        legend.key.height = unit(0.2, "cm"),
        legend.key.width = unit(0.2, "cm"),
        legend.background = element_blank(),
        plot.margin = unit(c(0, 0.25, 0.15, 0), "cm")) +
  NULL

write.csv(div_index_sim, "output/cod_fle_index.csv")
```

#### I want to explore the flounder model a little bit more before I trust it, because in contrast to cod, I haven't done so yet

```{r, cache=TRUE}
# Read in pred_grid which has oxygen values at location and time and depth:
pred_grid1 <- readr::read_csv("https://raw.githubusercontent.com/maxlindmark/cod_condition/master/data/for_analysis/pred_grid_(1_2).csv")
pred_grid2 <- readr::read_csv("https://raw.githubusercontent.com/maxlindmark/cod_condition/master/data/for_analysis/pred_grid_(2_2).csv")

pred_grid <- bind_rows(pred_grid1, pred_grid2)

# Standardize data with respect to prediction grid:
pred_grid2 <- pred_grid2 %>%
  mutate(year = as.integer(year)) %>% 
  filter(year %in% c(unique(d$year))) %>% 
  mutate(depth_sc = (depth - mean(d$depth))/sd(d$depth),
         temp_sc = (temp - mean(d$temp))/sd(d$temp),
         oxy_sc = (oxy - mean(d$oxy))/sd(d$oxy)) %>% # Need to scale these to the mean and sd in the data!
  drop_na(oxy, depth, temp)

# Predict on the pred grid, calculate index
preds_fle <- predict(mfle, newdata = pred_grid2, return_tmb_object = TRUE, area = 4*4)
index <- get_index(preds_fle, bias_correct = FALSE)
index <- index %>% mutate(est_t = est/1000, lwr_t = lwr/1000, upr_t = upr/1000)

# Plot index
ggplot() +
  geom_line(data = index, aes(year, est_t, color = "blue")) +
  geom_ribbon(data = index, aes(year, ymin = lwr_t, ymax = upr_t, fill = "blue"), alpha = 0.4) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 20)) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  guides(color = FALSE) + 
  labs(x = "Year", y = "Tonnes", fill = "Sub Divisions", label = "") +
  theme_light(base_size = 11) +
  theme(axis.text.x = element_text(angle = 30),
        legend.position = c(0.8, 0.8),
        legend.background = element_blank()) +
  NULL

# Calculate an index that corresponds to the average so that I can compare it to the data
ncells <- filter(pred_grid2, year == max(pred_grid2$year)) %>% nrow()
preds_fle_ave <- predict(mfle, newdata = pred_grid2, return_tmb_object = TRUE, area = 1/ncells)
index_ave <- get_index(preds_fle_ave, bias_correct = FALSE)

d_sum <- d %>%
  ungroup() %>%
  group_by(year) %>%
  summarise(mean_density_fle = mean(density_fle))

ggplot(index_ave, aes(year, est, color = "prediction")) +
  geom_line() +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = "prediction"), alpha = 0.1) +
  geom_point(data = d_sum, aes(year, mean_density_fle, color = "data", size = 1.1)) +
  geom_line(data = d_sum, aes(year, mean_density_fle, color = "data"), linetype = 2) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  guides(fill = FALSE) +
  labs(x = "Year", y = expression(paste("Density [kg/", km^2, "]", sep = ""))) +
  NULL

# Plot predictions on map
ggplot(swe_coast_proj) +
  geom_raster(data = preds_fle$data, aes(x = X * 1000, y = Y * 1000, fill = exp(est))) +
  geom_sf(size = 0.3) +
  scale_fill_viridis_c(trans = "sqrt") +
  facet_wrap(~ year, ncol = 5) +
  labs(x = "Longitude", y = "Latitude", fill = expression(kg/km^2)) +
  ggtitle("Predicted density (fixed + random)")

## Interesting! Now predict these model on dat - i.e. the condition data so that I can use those as covariates
```
