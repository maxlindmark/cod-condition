---
title: "Condition model: test small cod"
author: "Max Lindmark & Sean Andersson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE, cache=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 12,
  fig.asp = 0.618,
  fig.align ='center'
)
```

## Aim
Fit main model (see exploratory scripts and model comparison), visualize results.

## Fit models
### Read data and set up spde mesh
```{r packages, message=FALSE, warning=TRUE}
library(tidyverse); theme_set(theme_classic())
library(tidylog)
library(viridis)
library(sdmTMB) # remotes::install_github("pbs-assess/sdmTMB")
library(marmap)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(RColorBrewer)
library(gganimate)
library(gifski)
library(latex2exp)
library(patchwork)
library(png)
library(qwraps2) # To load entire cache in interactive r session, do: qwraps2::lazyload_cache_dir(path = "R/analysis/condition_model_cache/html")

# For adding maps to plots
world <- ne_countries(scale = "medium", returnclass = "sf")

# Specify map ranges
ymin = 54; ymax = 58; xmin = 9.5; xmax = 22
```

Now read data:

```{r read and process data, message=FALSE, warning=FALSE}
d <- readr::read_csv("https://raw.githubusercontent.com/maxlindmark/cod_condition/master/data/for_analysis/mdat_cond.csv")

# Calculate standardized variables
d <- d %>% 
  mutate(ln_length_cm = log(length_cm),
         ln_weight_g = log(weight_g),
         abun_her_sc = abun_her,
         abun_her_sd_sc = abun_her_sd,
         abun_spr_sc = abun_spr,
         abun_spr_sd_sc = abun_spr_sd,
         cpue_cod_sc = cpue_cod,
         cpue_cod_rec_sc = cpue_cod_rec,
         cpue_fle_sc = cpue_fle,
         cpue_fle_rec_sc = cpue_fle_rec,
         depth_sc = depth) %>%
  mutate_at(c("abun_her_sc", "abun_her_sd_sc", "abun_spr_sc", "abun_spr_sd_sc",
              "cpue_cod_sc", "cpue_cod_rec_sc", "cpue_fle_sc", "cpue_fle_rec_sc",
              "depth_sc"),
            ~(scale(.) %>% as.vector)) %>% 
  mutate(year = as.integer(year)) %>% 
  group_by(year) %>%
  mutate(oxy_sc = (oxy - mean(oxy))/sd(oxy),
         temp_sc = (temp - mean(temp))/sd(temp)) %>% 
  drop_na(abun_spr_sc, abun_her_sc) %>% 
  filter(length_cm < 30)
```

Read the prediction grids:

```{r read and process prediction grid, message=FALSE, warning=FALSE}
# pred_grid2 has oxygen and temp values at location and time and depth:
pred_grid2 <- readr::read_csv("https://raw.githubusercontent.com/maxlindmark/cod_condition/master/data/for_analysis/pred_grid2.csv")

pred_grid2 <- pred_grid2 %>% drop_na(oxy, depth, temp)

# Now standardize the variables in the data
pred_grid2 <- pred_grid2 %>%
  mutate(ln_length_cm = log(1)) %>% # For now we'll predict changes in the intercept ("condition factor")
  mutate(X = lon, Y = lat, year = as.integer(year)) %>% 
  filter(year %in% c(unique(d$year))) %>% 
  mutate(depth_sc = (depth - mean(d$depth))/sd(d$depth)) %>%
  group_by(year) %>% 
  ungroup() %>% 
  mutate(oxy_sc = (oxy - mean(d$oxy))/sd(d$oxy),
         temp_sc = (temp - mean(d$temp))/sd(d$temp))
  
# We centre the variable using the annual means in the data grid

# Explore the data
ggplot(pred_grid2, aes(depth, temp)) + geom_point() + stat_smooth() + coord_cartesian(xlim = c(40, 60))
ggplot(pred_grid2, aes(depth, oxy)) + geom_point() + stat_smooth() + coord_cartesian(xlim = c(46, 51), ylim = c(6.1, 6.4))
```

Make barrier spde mesh

```{r make barrier spde mesh, results='hide', message=FALSE}
# Crop the polygon for plotting and efficiency:
baltic_coast <- suppressWarnings(suppressMessages(
  st_crop(world,
          c(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax))))

crs <- 4326 # https://en.wikipedia.org/wiki/EPSG_Geodetic_Parameter_Dataset#Common_EPSG_codes, WGS84

st_crs(baltic_coast) <- 4326 # 'WGS84'; necessary on some installs
baltic_coast <- st_transform(baltic_coast, crs)

# Project our survey data coordinates:
survey <- d %>% dplyr::select(lon, lat, ln_weight_g) %>%
  st_as_sf(crs = 4326, coords = c("lon", "lat")) 

# Prepare for making the mesh
# First, we will extract the coordinates:
surv_coords <- st_coordinates(survey)

spde <- make_mesh(d, xy_cols = c("lon", "lat"),
                  n_knots = 180, # 180 works nice as well but 160 works with the 80% training data
                  type = "kmeans", seed = 42)

# Add on the barrier mesh component:
bspde <- add_barrier_mesh(
  spde, baltic_coast, range_fraction = 0.2,
  proj_scaling = 1, plot = TRUE
)

# In the above, the grey dots are the centre of triangles that are in the
# ocean. The red crosses are centres of triangles that are over land. The
# spatial range will be assumed to be 0.2 (`range_fraction`) over land compared
# to over water.

# We can make a more advanced plot if we want:
mesh_df_water <- bspde$mesh_sf[bspde$normal_triangles, ]
mesh_df_land <- bspde$mesh_sf[bspde$barrier_triangles, ]

# Now, when we fit our model with the new mesh, it will automatically
# include a barrier structure in the spatial correlation:
```

### Full model
```{r full model, cache=TRUE}
mfull <- sdmTMB(formula = ln_weight_g ~ ln_length_cm + depth_sc + oxy_sc + temp_sc + 
                  cpue_fle_sc + cpue_fle_rec_sc + cpue_cod_sc + cpue_cod_rec_sc + abun_spr_sc + abun_spr_sd_sc + abun_her_sc + abun_her_sd_sc + oxy_sc*depth_sc + temp_sc*depth_sc + oxy_sc*temp_sc 
                  -1, time_varying = ~ 1, data = d, time = "year",
                spde = bspde, family = student(link = "identity", df = 5), ar1_fields = TRUE,
                include_spatial = TRUE, spatial_trend = FALSE, spatial_only = FALSE,
                silent = TRUE, newton_steps = 1, reml = FALSE)

tidy(mfull, conf.int = TRUE)
```


### Plot fixed and random effects
```{r extract coefficients, message=FALSE}
# Extract random and fixed coefficients from the full model
mfull_est <- bind_rows(tidy(mfull, effects = "ran_par", conf.int = TRUE) %>%
                         filter(term %in% c("sigma_O", "sigma_E")),
                       tidy(mfull, effects = "fixed", conf.int = TRUE) %>%
                         filter(!term %in% c("ln_length_cm"))) %>%
  mutate(Model = "Oxygen model") %>%
  mutate(term = factor(term)) %>%
  mutate(term = recode(term,
                       "oxy_sc" = "Oxygen",
                       "temp_sc" = "Temp.",
                       "abun_her_sc" = "Herring",
                       "abun_her_sd_sc" = "Herring SD",
                       "abun_spr_sc" = "Sprat",
                       "abun_spr_sd_sc" = "Sprat SD",
                       "cpue_cod_sc" = "Cod",
                       "cpue_cod_rec_sc" = "Cod REC",
                       "cpue_fle_sc" = "Flounder",
                       "cpue_fle_rec_sc" = "Flounder rec",
                       "depth_sc:temp_sc" = "Depth X Temp.",
                       "depth_sc:oxy_sc" = "Depth X Oxygen",
                       "oxy_sc:temp_sc" = "Oxygen X Temp.",
                       "temp_sc:oxy_sc" = "Temp. X Oxygen",
                       "sigma_O" = 'σ_O (spatial\nrandom s.d.)',
                       "sigma_E" = 'σ_E (spatiotemporal\nrandom s.d.)',
                       "depth_sc" = "Depth"))

# Plot effects
ggplot(mfull_est, aes(reorder(term, estimate), estimate)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_hline(yintercept = 0, linetype = 2, color = "gray") +
  labs(x = "", y = "Standardized coefficient") +
  theme_classic(base_size = 16) +
  coord_flip()

ggsave("figures/supp/effect_sizes_small_cod_model.png", width = 5, height = 7.5, dpi = 600)
```

Plot the annual condition factor

```{r annual condition factor, message=FALSE,cache=TRUE}
# From these models, predict annual condition factor
# Grabbing the number of cells to help with calculating the average
ncells <- filter(pred_grid2, year == max(pred_grid2$year)) %>% nrow()

pred_grid_oxy <- pred_grid2 %>% drop_na(oxy)

pred_grid_oxy <- pred_grid_oxy %>% 
  mutate(cpue_fle_sc = 0,
         cpue_fle_rec_sc = 0,
         cpue_cod_sc = 0,
         cpue_cod_rec_sc = 0,
         abun_spr_sc = 0,
         abun_spr_sd_sc = 0,
         abun_her_sc = 0,
         abun_her_sd_sc = 0)

# For now I set all covariates to zero, but if we want to calculate annual averages with covariates (e.g. oxygen), then we should fit the model with oxygen centered to the mean in the prediction grid.

# Use the `area` argument here to turn the total into an average by giving it one over the number of cells
preds_mfull <- predict(mfull, newdata = pred_grid_oxy, return_tmb_object = TRUE, area = 1/ncells)

# Make a little helper function... bias correction shouldn't do anything here because of the identity link
get_average_condition <- function(obj, level = 0.95, ...)  {
  sdmTMB:::get_generic(obj, value_name = "link_total",
                       bias_correct = FALSE, level = level, trans = I, ...)
}

avg_mfull <- get_average_condition(preds_mfull)

avg_mfull %>%
  ggplot(., aes(year, est)) +
  ylab("Average log(condition factor)") +
  geom_point(size = 2) +
  geom_errorbar(aes(x = year, ymax = upr, ymin = lwr),
                width = 0.2, alpha = 0.8) +
  theme(axis.text.x = element_text(angle = 30),
        legend.position = c(0.8, 0.8)) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
  labs(x = "Year") +
  theme_classic(base_size = 14) + 
  theme(aspect.ratio = 0.75) +
  NULL

ggsave("figures/supp/condition_index_small_cod_model.png", width = 6.5, height = 6.5, dpi = 600)
```
